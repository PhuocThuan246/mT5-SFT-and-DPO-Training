{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:31:38.710298Z",
     "iopub.status.busy": "2025-11-16T10:31:38.710028Z",
     "iopub.status.idle": "2025-11-16T10:32:59.024823Z",
     "shell.execute_reply": "2025-11-16T10:32:59.023805Z",
     "shell.execute_reply.started": "2025-11-16T10:31:38.710276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate sentencepiece -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T18:55:36.606495Z",
     "iopub.status.busy": "2025-11-15T18:55:36.606224Z",
     "iopub.status.idle": "2025-11-15T18:55:38.758472Z",
     "shell.execute_reply": "2025-11-15T18:55:38.757403Z",
     "shell.execute_reply.started": "2025-11-15T18:55:36.606462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch, json, re\n",
    "\n",
    "model_id = \"Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model_qwen = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:02:33.528569Z",
     "iopub.status.busy": "2025-11-15T17:02:33.527838Z",
     "iopub.status.idle": "2025-11-15T17:02:33.533888Z",
     "shell.execute_reply": "2025-11-15T17:02:33.532816Z",
     "shell.execute_reply.started": "2025-11-15T17:02:33.528543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def qwen_generate(prompt, max_tokens=512):\n",
    "    \"\"\"Sinh văn bản bằng Qwen (Instruct).\"\"\"\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model_qwen.device)\n",
    "\n",
    "    output = model_qwen.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:02:35.746987Z",
     "iopub.status.busy": "2025-11-15T17:02:35.746425Z",
     "iopub.status.idle": "2025-11-15T17:02:35.751499Z",
     "shell.execute_reply": "2025-11-15T17:02:35.750674Z",
     "shell.execute_reply.started": "2025-11-15T17:02:35.746961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_output(raw):\n",
    "    # Xóa các ký tự lạ ngoài ASCII + tiếng Việt\n",
    "    raw = re.sub(r\"[^\\x00-\\x7FÀ-ỹ\\s.,!?\\\"'“”‘’\\-:/()]\", \"\", raw)\n",
    "    # Xóa bớt khoảng trắng dư\n",
    "    raw = re.sub(r\"\\s+\", \" \", raw)\n",
    "    return raw.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:02:37.523183Z",
     "iopub.status.busy": "2025-11-15T17:02:37.522474Z",
     "iopub.status.idle": "2025-11-15T17:02:37.530699Z",
     "shell.execute_reply": "2025-11-15T17:02:37.529801Z",
     "shell.execute_reply.started": "2025-11-15T17:02:37.523151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "def generate_dpo_batch(batch_size=20):\n",
    "    prompt = f\"\"\"\n",
    "Generate {batch_size} SIMPLE DPO samples for English→Vietnamese translation.\n",
    "\n",
    "Each sample must be ONE JSON object with EXACTLY these keys:\n",
    "{{\n",
    "  \"prompt\": \"<simple English sentence>\",\n",
    "  \"chosen\": \"<correct Vietnamese translation>\",\n",
    "  \"rejected\": \"<slightly incorrect Vietnamese translation>\"\n",
    "}}\n",
    "\n",
    "### RULES ###\n",
    "- English sentences MUST be SIMPLE:\n",
    "- English sentence MUST BE 8–25 words.\n",
    "- Vietnamese sentence MUST BE 8–25 words.\n",
    "- Diverse topics: daily life, education, technology, science, society.\n",
    "- \"chosen\" MUST be a 100% faithful and literal translation.\n",
    "- \"rejected\" must contain a small mistake (wrong word, missing word, extra word).\n",
    "- \"rejected\" MUST NOT be identical to \"chosen\".\n",
    "- NO explanation. NO numbering. NO extra text.\n",
    "\n",
    "### OUTPUT FORMAT ###\n",
    "(Repeat EXACTLY {batch_size} JSON objects, one after another)\n",
    "\n",
    "Begin output NOW:\n",
    "\"\"\"\n",
    "\n",
    "    raw = qwen_generate(prompt, max_tokens=2000)\n",
    "    raw = clean_output(raw)\n",
    "\n",
    "    idx = raw.lower().rfind(\"assistant\")\n",
    "    if idx != -1:\n",
    "        raw = raw[idx + len(\"assistant\"):].strip()\n",
    "\n",
    "    json_blocks = re.findall(r\"\\{.*?\\}\", raw)\n",
    "\n",
    "    results = []\n",
    "    for block in json_blocks:\n",
    "        try:\n",
    "            data = json.loads(block)\n",
    "            if (\n",
    "                isinstance(data.get(\"prompt\"), str) and\n",
    "                isinstance(data.get(\"chosen\"), str) and\n",
    "                isinstance(data.get(\"rejected\"), str)\n",
    "            ):\n",
    "                results.append(data)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if not results:\n",
    "        print(\"Không parse được JSON nào!\\nRaw:\\n\", raw)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:02:40.198535Z",
     "iopub.status.busy": "2025-11-15T17:02:40.197820Z",
     "iopub.status.idle": "2025-11-15T17:02:40.204890Z",
     "shell.execute_reply": "2025-11-15T17:02:40.204143Z",
     "shell.execute_reply.started": "2025-11-15T17:02:40.198500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_dpo_bulk(total=200, batch=20):\n",
    "    all_results = []\n",
    "    loops = total // batch\n",
    "\n",
    "    for i in range(loops):\n",
    "        print(f\"[DPO] Batch {i+1}/{loops} ...\")\n",
    "        part = generate_dpo_batch(batch_size=batch)\n",
    "        all_results.extend(part)\n",
    "\n",
    "    remain = total % batch\n",
    "    if remain > 0:\n",
    "        print(f\"[DPO] Last batch: {remain} ...\")\n",
    "        part = generate_dpo_batch(batch_size=remain)\n",
    "        all_results.extend(part)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:06:26.049839Z",
     "iopub.status.busy": "2025-11-15T17:06:26.049097Z",
     "iopub.status.idle": "2025-11-15T17:28:31.649379Z",
     "shell.execute_reply": "2025-11-15T17:28:31.648522Z",
     "shell.execute_reply.started": "2025-11-15T17:06:26.049810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dpo_result = generate_dpo_bulk(total=500, batch=20)\n",
    "print(\"Tổng số mẫu DPO:\", len(dpo_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:30:17.964514Z",
     "iopub.status.busy": "2025-11-15T17:30:17.963890Z",
     "iopub.status.idle": "2025-11-15T17:30:17.969149Z",
     "shell.execute_reply": "2025-11-15T17:30:17.968423Z",
     "shell.execute_reply.started": "2025-11-15T17:30:17.964486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# In 10 dòng đầu tiên trong dataset DPO\n",
    "for item in dpo_result[:10]:\n",
    "    print({\n",
    "        \"prompt\": item[\"prompt\"],\n",
    "        \"chosen\": item[\"chosen\"],\n",
    "        \"rejected\": item[\"rejected\"]\n",
    "    })\n",
    "    print()  # dòng trống cho dễ nhìn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T17:30:38.546436Z",
     "iopub.status.busy": "2025-11-15T17:30:38.545729Z",
     "iopub.status.idle": "2025-11-15T17:30:38.554056Z",
     "shell.execute_reply": "2025-11-15T17:30:38.553442Z",
     "shell.execute_reply.started": "2025-11-15T17:30:38.546409Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_path = \"dpo_dataset.jsonl\"\n",
    "\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in dpo_result:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Đã lưu file:\", save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chạy lại model SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T20:33:09.938277Z",
     "iopub.status.busy": "2025-11-15T20:33:09.937534Z",
     "iopub.status.idle": "2025-11-15T20:34:20.542496Z",
     "shell.execute_reply": "2025-11-15T20:34:20.541271Z",
     "shell.execute_reply.started": "2025-11-15T20:33:09.938248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate sentencepiece -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:33:17.537165Z",
     "iopub.status.busy": "2025-11-16T10:33:17.536849Z",
     "iopub.status.idle": "2025-11-16T10:33:54.260408Z",
     "shell.execute_reply": "2025-11-16T10:33:54.259799Z",
     "shell.execute_reply.started": "2025-11-16T10:33:17.537135Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 10:33:32.566651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763289212.754566      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763289212.806858      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ce136044ea440ab6a09e7b254cc100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f303ce3994ca4103aa74b90bda51f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-8fc21cb8e80d3a(…):   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c96cee5e9e74d6fa1675f01392c1648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001-858c0e989d9c563(…):   0%|          | 0.00/1.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0100b09e7e0b441f9cad7e20e2a24d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/valid-00000-of-00001-99e7e50144d1c1(…):   0%|          | 0.00/1.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a0b37aadda41b0951a6a2f3f6b7c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/203272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cca41ce24c44afd965e7a160151bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2224f1e0123f4577b9816d4e1dd8744d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/25409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments\n",
    ")\n",
    "import torch\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DỮ LIỆU SONG NGỮ\n",
    "# ============================================================\n",
    "dataset = load_dataset(\n",
    "    \"harouzie/vi_en-translation\",\n",
    "    split=\"train\",\n",
    "    token=\"\"\n",
    ").shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# ============================================================\n",
    "# CHIA TẬP TRAIN / TEST\n",
    "# ============================================================\n",
    "split_ds = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds, eval_ds = split_ds[\"train\"], split_ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:01.559622Z",
     "iopub.status.busy": "2025-11-16T10:34:01.558409Z",
     "iopub.status.idle": "2025-11-16T10:34:01.566694Z",
     "shell.execute_reply": "2025-11-16T10:34:01.565808Z",
     "shell.execute_reply.started": "2025-11-16T10:34:01.559594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['English', 'Vietnamese'],\n",
      "    num_rows: 4500\n",
      "})\n",
      "Dataset({\n",
      "    features: ['English', 'Vietnamese'],\n",
      "    num_rows: 500\n",
      "})\n",
      "\n",
      "Dữ liệu trong tập train:\n",
      "\n",
      "English: Is there a tennis court around here?\n",
      "Vietnamese: Có một sân tennis quanh đây không?\n",
      "\n",
      "English: I want you to promise me something.\n",
      "Vietnamese: tôi muốn bạn hứa với tôi một cái gì đó\n",
      "\n",
      "English: Thank you for your kind assistance.\n",
      "Vietnamese: cảm ơn sự giúp đỡ của bạn\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print(eval_ds)\n",
    "# ============================================================\n",
    "print(\"\\nDữ liệu trong tập train:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nEnglish: {train_ds[i]['English']}\")\n",
    "    print(f\"Vietnamese: {train_ds[i]['Vietnamese']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T20:35:14.061919Z",
     "iopub.status.busy": "2025-11-15T20:35:14.061260Z",
     "iopub.status.idle": "2025-11-15T20:35:37.540641Z",
     "shell.execute_reply": "2025-11-15T20:35:37.539621Z",
     "shell.execute_reply.started": "2025-11-15T20:35:14.061886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_path = \"/kaggle/input/mt5-envit5-style/mt5_envit5_style\"\n",
    "\n",
    "# Load model và tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32   # hoặc bfloat16 nếu GPU hỗ trợ\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "print(\"Model và tokenizer đã được load thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T20:35:40.722864Z",
     "iopub.status.busy": "2025-11-15T20:35:40.722321Z",
     "iopub.status.idle": "2025-11-15T20:35:40.728461Z",
     "shell.execute_reply": "2025-11-15T20:35:40.727564Z",
     "shell.execute_reply.started": "2025-11-15T20:35:40.722830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_en_to_vi(text):\n",
    "    input_text = \"translate English to Vietnamese: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=128).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T20:35:42.835483Z",
     "iopub.status.busy": "2025-11-15T20:35:42.835194Z",
     "iopub.status.idle": "2025-11-15T20:35:46.268729Z",
     "shell.execute_reply": "2025-11-15T20:35:46.267924Z",
     "shell.execute_reply.started": "2025-11-15T20:35:42.835463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test_sentences = [\n",
    "    \"She is my best friend.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"Can you help me?\",\n",
    "    \"Please open the door.\",\n",
    "    \"He didn’t come yesterday.\",\n",
    "    \"They are playing football.\",\n",
    "    \"It’s time to go home.\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(f\"\\nEnglish: {s}\")\n",
    "    print(f\"Vietnamese: {translate_en_to_vi(s)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:56:20.863841Z",
     "iopub.status.busy": "2025-11-16T10:56:20.863533Z",
     "iopub.status.idle": "2025-11-16T10:56:25.048022Z",
     "shell.execute_reply": "2025-11-16T10:56:25.046934Z",
     "shell.execute_reply.started": "2025-11-16T10:56:20.863818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker, sacrebleu\n",
      "Successfully installed portalocker-3.2.0 sacrebleu-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:08.355217Z",
     "iopub.status.busy": "2025-11-16T10:34:08.354484Z",
     "iopub.status.idle": "2025-11-16T10:34:21.362326Z",
     "shell.execute_reply": "2025-11-16T10:34:21.361394Z",
     "shell.execute_reply.started": "2025-11-16T10:34:08.355190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch, json, re\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# model SFT dùng để train DPO\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"/kaggle/input/mt5-envit5-style/mt5_envit5_style\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "\n",
    "# model tham chiếu\n",
    "model_ref = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"/kaggle/input/mt5-envit5-style/mt5_envit5_style\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "model_ref.eval()\n",
    "for p in model_ref.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/mt5-envit5-style/mt5_envit5_style\")\n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:25.637585Z",
     "iopub.status.busy": "2025-11-16T10:34:25.637206Z",
     "iopub.status.idle": "2025-11-16T10:34:25.643610Z",
     "shell.execute_reply": "2025-11-16T10:34:25.642841Z",
     "shell.execute_reply.started": "2025-11-16T10:34:25.637557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_logprob(model, tokenizer, x, y):\n",
    "    # Encode input\n",
    "    inputs = tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH).to(device)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(y, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH).input_ids.to(device)\n",
    "    # Forward\n",
    "    out = model(**inputs, labels=labels)\n",
    "    # log-softmax over vocab\n",
    "    log_probs = out.logits.log_softmax(-1)\n",
    "    # Lấy log-prob token đúng: gather theo labels\n",
    "    token_logprobs = torch.gather(log_probs, 2, labels.unsqueeze(-1)).squeeze(-1)\n",
    "    # Padding có label = -100, bỏ đi\n",
    "    mask = (labels != -100).float()\n",
    "     # log-prob normalized theo số token\n",
    "    return (token_logprobs * mask).sum() / mask.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:28.162026Z",
     "iopub.status.busy": "2025-11-16T10:34:28.161233Z",
     "iopub.status.idle": "2025-11-16T10:34:28.168373Z",
     "shell.execute_reply": "2025-11-16T10:34:28.167520Z",
     "shell.execute_reply.started": "2025-11-16T10:34:28.161993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dpo_loss(model, model_ref, tokenizer, x, chosen, rejected, beta=0.1):\n",
    "    model.train()\n",
    "    # Log-probability: p_theta(chosen | x)\n",
    "    log_p_w = compute_logprob(model, tokenizer, x, chosen)\n",
    "     # Log-probability: p_theta(rejected | x)\n",
    "    log_p_l = compute_logprob(model, tokenizer, x, rejected)\n",
    "    # Đánh giá log-probability dựa trên model tham chiếu (fixed)\n",
    "    with torch.no_grad():\n",
    "        log_ref_w = compute_logprob(model_ref, tokenizer, x, chosen)\n",
    "        log_ref_l = compute_logprob(model_ref, tokenizer, x, rejected)\n",
    "\n",
    "    z = beta * ((log_p_w - log_ref_w) - (log_p_l - log_ref_l))\n",
    "    # Loss DPO: -log(sigmoid(z))\n",
    "    loss = -F.logsigmoid(z)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:30.428971Z",
     "iopub.status.busy": "2025-11-16T10:34:30.428676Z",
     "iopub.status.idle": "2025-11-16T10:34:30.453446Z",
     "shell.execute_reply": "2025-11-16T10:34:30.452641Z",
     "shell.execute_reply.started": "2025-11-16T10:34:30.428949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số mẫu: 2000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(\"/kaggle/input/dpo-datasetv5-jsonl/dpo_datasetV5.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # bỏ dòng trống\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            data.append(obj)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Dòng lỗi JSON:\", line)\n",
    "            continue\n",
    "print(\"Tổng số mẫu:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:32.092284Z",
     "iopub.status.busy": "2025-11-16T10:34:32.091447Z",
     "iopub.status.idle": "2025-11-16T10:34:32.097295Z",
     "shell.execute_reply": "2025-11-16T10:34:32.096291Z",
     "shell.execute_reply.started": "2025-11-16T10:34:32.092258Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE 1 ---\n",
      "prompt:   I love reading books.\n",
      "chosen:   Tôi yêu thích đọc sách.\n",
      "rejected: Tôi thích đọc sách và viết.\n",
      "\n",
      "--- SAMPLE 2 ---\n",
      "prompt:   The cat is sleeping on the sofa.\n",
      "chosen:   Con mèo đang ngủ trên ghế sofa.\n",
      "rejected: Chú mèo đang nằm trên chiếc sofa.\n",
      "\n",
      "--- SAMPLE 3 ---\n",
      "prompt:   She teaches English at a university.\n",
      "chosen:    Cô ấy dạy tiếng Anh tại một trường đại học.\n",
      "rejected: Cô ấy giảng dạy tiếng Anh trong một trường đại học.\n",
      "\n",
      "--- SAMPLE 4 ---\n",
      "prompt:   They built a new bridge last year.\n",
      "chosen:   Họ đã xây dựng một cây cầu mới vào năm ngoái.\n",
      "rejected: Họ đã xây dựng một cây cầu cũ vào năm qua.\n",
      "\n",
      "--- SAMPLE 5 ---\n",
      "prompt:   He studies computer science.\n",
      "chosen:   Anh ấy học khoa học máy tính.\n",
      "rejected: Anh ấy học khoa học máy tính và điện tử.\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(data[:5], 1):\n",
    "    print(f\"\\n--- SAMPLE {i} ---\")\n",
    "    print(\"prompt:  \", item.get(\"prompt\"))\n",
    "    print(\"chosen:  \", item.get(\"chosen\"))\n",
    "    print(\"rejected:\", item.get(\"rejected\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:34.120426Z",
     "iopub.status.busy": "2025-11-16T10:34:34.120118Z",
     "iopub.status.idle": "2025-11-16T10:34:34.126242Z",
     "shell.execute_reply": "2025-11-16T10:34:34.125201Z",
     "shell.execute_reply.started": "2025-11-16T10:34:34.120404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE 1996 ---\n",
      "prompt:   She organized a virtual reunion with her college friends.\n",
      "chosen:   Cô ấy đã tổ chức một buổi họp mặt trực tuyến với bạn đại học.\n",
      "rejected: Cô ấy tán gẫu với robot và gọi đó là họp lớp.\n",
      "\n",
      "--- SAMPLE 1997 ---\n",
      "prompt:   He delivered the package to the wrong address.\n",
      "chosen:   Anh ấy đã giao nhầm địa chỉ.\n",
      "rejected: Anh ấy giữ gói hàng làm của riêng và gọi đó là tái chế vật phẩm.\n",
      "\n",
      "--- SAMPLE 1998 ---\n",
      "prompt:   She wore a helmet while riding her bike.\n",
      "chosen:   Cô ấy đã đội mũ bảo hiểm khi đạp xe.\n",
      "rejected: Cô ấy đội mũ bơi khi đạp xe để chống mưa.\n",
      "\n",
      "--- SAMPLE 1999 ---\n",
      "prompt:   He folded the laundry and put it away.\n",
      "chosen:   Anh ấy đã gấp quần áo và cất đi.\n",
      "rejected: Anh ấy gấp quần áo thành hình con thỏ rồi trang trí phòng khách.\n",
      "\n",
      "--- SAMPLE 2000 ---\n",
      "prompt:   They replaced the old roof with solar shingles.\n",
      "chosen:   Họ đã thay mái nhà cũ bằng mái năng lượng mặt trời.\n",
      "rejected: Họ sơn mái nhà thành màu xanh và gọi đó là năng lượng mới.\n"
     ]
    }
   ],
   "source": [
    "# Giả sử data đã được load sẵn từ file JSONL\n",
    "# In ra 5 dòng cuối\n",
    "for i, item in enumerate(data[-5:], len(data) - 4):\n",
    "    print(f\"\\n--- SAMPLE {i} ---\")\n",
    "    print(\"prompt:  \", item.get(\"prompt\"))\n",
    "    print(\"chosen:  \", item.get(\"chosen\"))\n",
    "    print(\"rejected:\", item.get(\"rejected\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:36.969977Z",
     "iopub.status.busy": "2025-11-16T10:34:36.969687Z",
     "iopub.status.idle": "2025-11-16T10:34:36.976562Z",
     "shell.execute_reply": "2025-11-16T10:34:36.975832Z",
     "shell.execute_reply.started": "2025-11-16T10:34:36.969957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu mẫu đầu tiên:\n",
      "{\n",
      "  \"prompt\": \"I love reading books.\",\n",
      "  \"chosen\": \"Tôi yêu thích đọc sách.\",\n",
      "  \"rejected\": \"Tôi thích đọc sách và viết.\"\n",
      "}\n",
      "\n",
      "Tổng dòng dữ liệu: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dữ liệu mẫu đầu tiên:\")\n",
    "print(json.dumps(data[0], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\nTổng dòng dữ liệu:\", len(data))\n",
    "\n",
    "# Kiểm tra tất cả dòng có 3 key\n",
    "for i, item in enumerate(data):\n",
    "    if not all(k in item for k in [\"prompt\", \"chosen\", \"rejected\"]):\n",
    "        print(f\"Dòng {i} bị lỗi:\", item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:38.973306Z",
     "iopub.status.busy": "2025-11-16T10:34:38.972920Z",
     "iopub.status.idle": "2025-11-16T10:34:38.994073Z",
     "shell.execute_reply": "2025-11-16T10:34:38.993283Z",
     "shell.execute_reply.started": "2025-11-16T10:34:38.973263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized prompt: tensor([ 37194,   5413,    288,    259, 134126,    267,    336,   3869,  11807,\n",
      "         20743,    260,      1])\n",
      "Tokenized chosen: tensor([ 366, 3571,  259, 3565,  273,  394, 2986,  355, 4929,  259,  263, 1833,\n",
      "         260,    1])\n",
      "Tokenized rejected: tensor([ 366, 3571,  394, 2986,  355, 4929,  259,  263, 1833,  259,  793,  300,\n",
      "        2591,  260,    1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Chọn 1 mẫu bất kỳ\n",
    "sample = data[0]\n",
    "x = \"translate English to Vietnamese: \" + sample[\"prompt\"]\n",
    "chosen = sample[\"chosen\"]\n",
    "rejected = sample[\"rejected\"]\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(x, return_tensors=\"pt\", max_length=128, truncation=True, padding=True)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    chosen_labels = tokenizer(chosen, return_tensors=\"pt\", max_length=128, truncation=True, padding=True).input_ids\n",
    "    rejected_labels = tokenizer(rejected, return_tensors=\"pt\", max_length=128, truncation=True, padding=True).input_ids\n",
    "\n",
    "print(\"\\nTokenized prompt:\", inputs[\"input_ids\"][0][:20])\n",
    "print(\"Tokenized chosen:\", chosen_labels[0][:20])\n",
    "print(\"Tokenized rejected:\", rejected_labels[0][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:34:41.753450Z",
     "iopub.status.busy": "2025-11-16T10:34:41.752731Z",
     "iopub.status.idle": "2025-11-16T10:34:42.379749Z",
     "shell.execute_reply": "2025-11-16T10:34:42.378783Z",
     "shell.execute_reply.started": "2025-11-16T10:34:41.753414Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "log_p_chosen = -0.8322564959526062\n",
      "log_p_rejected = -1.3593159914016724\n"
     ]
    }
   ],
   "source": [
    "log_p_chosen = compute_logprob(model, tokenizer, x, chosen)\n",
    "log_p_rejected = compute_logprob(model, tokenizer, x, rejected)\n",
    "\n",
    "print(\"\\nlog_p_chosen =\", log_p_chosen.item())\n",
    "print(\"log_p_rejected =\", log_p_rejected.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:35:00.925929Z",
     "iopub.status.busy": "2025-11-16T10:35:00.925014Z",
     "iopub.status.idle": "2025-11-16T10:55:33.266191Z",
     "shell.execute_reply": "2025-11-16T10:55:33.265510Z",
     "shell.execute_reply.started": "2025-11-16T10:35:00.925894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/500 | Loss = 0.7443\n",
      "Step 20/500 | Loss = 0.7853\n",
      "Step 40/500 | Loss = 0.8000\n",
      "Step 60/500 | Loss = 0.7520\n",
      "Step 80/500 | Loss = 0.7804\n",
      "Step 100/500 | Loss = 0.6884\n",
      "Step 120/500 | Loss = 0.7769\n",
      "Step 140/500 | Loss = 0.8192\n",
      "Step 160/500 | Loss = 0.7800\n",
      "Step 180/500 | Loss = 0.7528\n",
      "Step 200/500 | Loss = 0.7377\n",
      "Step 220/500 | Loss = 0.7657\n",
      "Step 240/500 | Loss = 0.8349\n",
      "Step 260/500 | Loss = 0.7712\n",
      "Step 280/500 | Loss = 0.7668\n",
      "Step 300/500 | Loss = 0.7875\n",
      "Step 320/500 | Loss = 0.8227\n",
      "Step 340/500 | Loss = 0.8362\n",
      "Step 360/500 | Loss = 0.8104\n",
      "Step 380/500 | Loss = 0.7706\n",
      "Step 400/500 | Loss = 0.8302\n",
      "Step 420/500 | Loss = 0.7577\n",
      "Step 440/500 | Loss = 0.8521\n",
      "Step 460/500 | Loss = 0.8571\n",
      "Step 480/500 | Loss = 0.8507\n"
     ]
    }
   ],
   "source": [
    "# --------- Training ----------\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)   # LR hợp lý cho DPO\n",
    "BATCH = 4\n",
    "\n",
    "steps = len(data) // BATCH\n",
    "\n",
    "for step in range(steps):\n",
    "    batch = data[step*BATCH : (step+1)*BATCH]\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for ex in batch:\n",
    "        # PROMPT INSTRUCTION \n",
    "        x = \"translate English to Vietnamese: \" + ex[\"prompt\"]\n",
    "\n",
    "        loss = dpo_loss(model, model_ref, tokenizer, x, ex[\"chosen\"], ex[\"rejected\"])\n",
    "        total_loss += loss\n",
    "\n",
    "    # >>> CHIA LOSS CHO BATCH (bắt buộc) <<<\n",
    "    total_loss = total_loss / BATCH\n",
    "\n",
    "    # backward\n",
    "    total_loss.backward()\n",
    "\n",
    "    # >>> GRADIENT CLIPPING <<<\n",
    "    clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 20 == 0:\n",
    "        print(f\"Step {step}/{steps} | Loss = {total_loss.item():.4f}\")\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:55:45.330427Z",
     "iopub.status.busy": "2025-11-16T10:55:45.330119Z",
     "iopub.status.idle": "2025-11-16T10:55:48.476415Z",
     "shell.execute_reply": "2025-11-16T10:55:48.475501Z",
     "shell.execute_reply.started": "2025-11-16T10:55:45.330404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt5_envit5_dpo/tokenizer_config.json',\n",
       " './mt5_envit5_dpo/special_tokens_map.json',\n",
       " './mt5_envit5_dpo/spiece.model',\n",
       " './mt5_envit5_dpo/added_tokens.json',\n",
       " './mt5_envit5_dpo/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./mt5_envit5_dpo/\")\n",
    "tokenizer.save_pretrained(\"./mt5_envit5_dpo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:45:31.606094Z",
     "iopub.status.busy": "2025-11-16T11:45:31.605765Z",
     "iopub.status.idle": "2025-11-16T11:47:37.725458Z",
     "shell.execute_reply": "2025-11-16T11:47:37.724611Z",
     "shell.execute_reply.started": "2025-11-16T11:45:31.606072Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nén thành công: ./mt5_envit5_dpo.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Đường dẫn thư mục và file zip\n",
    "folder_path = \"./mt5_envit5_dpo\"\n",
    "zip_path = \"./mt5_envit5_dpo.zip\"\n",
    "\n",
    "# Nén thành ZIP\n",
    "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', folder_path)\n",
    "\n",
    "print(\"Đã nén thành công:\", zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:55:50.893870Z",
     "iopub.status.busy": "2025-11-16T10:55:50.893551Z",
     "iopub.status.idle": "2025-11-16T10:55:52.597677Z",
     "shell.execute_reply": "2025-11-16T10:55:52.596707Z",
     "shell.execute_reply.started": "2025-11-16T10:55:50.893848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model và tokenizer đã được load thành công!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_path = \"./mt5_envit5_dpo/\"\n",
    "\n",
    "# Load model và tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16   \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "print(\"Model và tokenizer đã được load thành công!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:55:54.588018Z",
     "iopub.status.busy": "2025-11-16T10:55:54.587715Z",
     "iopub.status.idle": "2025-11-16T10:55:54.596447Z",
     "shell.execute_reply": "2025-11-16T10:55:54.595538Z",
     "shell.execute_reply.started": "2025-11-16T10:55:54.587995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_en_to_vi(text):\n",
    "    input_text = \"translate English to Vietnamese: \" + text\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=128).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T10:55:57.073002Z",
     "iopub.status.busy": "2025-11-16T10:55:57.072616Z",
     "iopub.status.idle": "2025-11-16T10:56:00.494334Z",
     "shell.execute_reply": "2025-11-16T10:56:00.493499Z",
     "shell.execute_reply.started": "2025-11-16T10:55:57.072973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English: She is my best friend.\n",
      "Vietnamese: cô ấy là bạn bè của tôi.\n",
      "\n",
      "English: The weather is nice today.\n",
      "Vietnamese: hôm nay thời tiết tuyệt\n",
      "\n",
      "English: Can you help me?\n",
      "Vietnamese: bạn có thể giúp tôi không?\n",
      "\n",
      "English: Please open the door.\n",
      "Vietnamese: vui lòng mở cửa.\n",
      "\n",
      "English: He didn’t come yesterday.\n",
      "Vietnamese: anh ấy đã không đến hôm qua.\n",
      "\n",
      "English: They are playing football.\n",
      "Vietnamese: họ đang chơi bóng đá.\n",
      "\n",
      "English: It’s time to go home.\n",
      "Vietnamese: đã đến lúc về nhà.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_sentences = [\n",
    "    \"She is my best friend.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"Can you help me?\",\n",
    "    \"Please open the door.\",\n",
    "    \"He didn’t come yesterday.\",\n",
    "    \"They are playing football.\",\n",
    "    \"It’s time to go home.\"\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(f\"\\nEnglish: {s}\")\n",
    "    print(f\"Vietnamese: {translate_en_to_vi(s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:02:23.535791Z",
     "iopub.status.busy": "2025-11-16T11:02:23.534938Z",
     "iopub.status.idle": "2025-11-16T11:02:24.330105Z",
     "shell.execute_reply": "2025-11-16T11:02:24.329426Z",
     "shell.execute_reply.started": "2025-11-16T11:02:23.535765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải dữ liệu gốc...\n",
      "Tổng số mẫu: 203272\n",
      "Tổng số mẫu test: 1000\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# Load & shuffle dataset giống hệt SFT (seed=42)\n",
    "# ============================================================\n",
    "print(\"Đang tải dữ liệu gốc...\")\n",
    "full_ds = load_dataset(\n",
    "    \"harouzie/vi_en-translation\",\n",
    "    split=\"train\",\n",
    "    token=\"\"\n",
    ").shuffle(seed=42)\n",
    "print(\"Tổng số mẫu:\", len(full_ds))\n",
    "\n",
    "# ============================================================\n",
    "# 1k câu cho test\n",
    "# ============================================================\n",
    "test_ds = full_ds.select(range(7000, 8000))  # 1000 mẫu Test\n",
    "print(\"Tổng số mẫu test:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:02:27.739457Z",
     "iopub.status.busy": "2025-11-16T11:02:27.738805Z",
     "iopub.status.idle": "2025-11-16T11:11:29.429994Z",
     "shell.execute_reply": "2025-11-16T11:11:29.429090Z",
     "shell.execute_reply.started": "2025-11-16T11:02:27.739433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating SFT Model =====\n",
      "SFT Model BLEU: 40.85\n",
      "\n",
      "===== Evaluating RL Model =====\n",
      "RL Model BLEU: 40.93\n",
      "\n",
      "===== SAMPLE TRANSLATIONS =====\n",
      "\n",
      "EN: We're competitors, not partners.\n",
      "SFT: chúng tôi không phải là khách hàng, không phải bạn.\n",
      "RL : chúng tôi không phải là khách hàng, không phải bạn.\n",
      "REF: chúng tôi là đối thủ cạnh tranh, không phải đối tác.\n",
      "\n",
      "EN: Nothing makes Tom happy\n",
      "SFT: không có gì làm tom hạnh phúc\n",
      "RL : không có gì làm tom hạnh phúc\n",
      "REF: không có gì làm cho tom hạnh phúc\n",
      "\n",
      "EN: Tom doesn't understand because he wasn't paying attention\n",
      "SFT: Tom không hiểu vì anh ấy không quan tâm\n",
      "RL : Tom không hiểu vì anh ấy không quan tâm\n",
      "REF: tom không hiểu vì anh không chú ý\n",
      "\n",
      "EN: She is in the wrong\n",
      "SFT: cô ấy đang sai\n",
      "RL : cô ấy đang sai\n",
      "REF: Cô là sai\n",
      "\n",
      "EN: Why did you want us to come here?\n",
      "SFT: Tại sao bạn muốn chúng tôi đến đây?\n",
      "RL : Tại sao bạn muốn chúng tôi đến đây?\n",
      "REF: tại sao bạn muốn chúng tôi đến đây?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import sacrebleu\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# HÀM DỊCH & ĐÁNH GIÁ BLEU\n",
    "# ============================================================\n",
    "def translate_batch(model, tokenizer, texts, max_samples=500):\n",
    "    translations = []\n",
    "    total = min(max_samples, len(texts))\n",
    "    for i, text in enumerate(texts[:total], start=1):\n",
    "        input_text = \"translate English to Vietnamese: \" + text\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=128).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=128,\n",
    "                num_beams=4,\n",
    "                do_sample=False\n",
    "            )\n",
    "        trans = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        translations.append(trans)\n",
    "    return translations\n",
    "\n",
    "def evaluate_bleu(model_path, test_data, label):\n",
    "    print(f\"\\n===== Evaluating {label} =====\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    sources = [ex[\"English\"] for ex in test_data]\n",
    "    references = [[ex[\"Vietnamese\"] for ex in test_data]]\n",
    "    translations = translate_batch(model, tokenizer, sources, max_samples=500)\n",
    "\n",
    "    bleu = sacrebleu.corpus_bleu(translations, references)\n",
    "    print(f\"{label} BLEU: {bleu.score:.2f}\")\n",
    "\n",
    "    return bleu.score, translations\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ĐÁNH GIÁ CẢ 2 MÔ HÌNH\n",
    "# ============================================================\n",
    "bleu_sft, trans_sft = evaluate_bleu(\"/kaggle/input/mt5-envit5-style/mt5_envit5_style\", test_ds, \"SFT Model\")\n",
    "bleu_rl, trans_rl = evaluate_bleu(\"./mt5_envit5_dpo/\", test_ds, \"RL Model\")\n",
    "\n",
    "# ============================================================\n",
    "# HIỂN THỊ MỘT SỐ VÍ DỤ\n",
    "# ============================================================\n",
    "print(\"\\n===== SAMPLE TRANSLATIONS =====\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nEN: {test_ds[i]['English']}\")\n",
    "    print(f\"SFT: {trans_sft[i]}\")\n",
    "    print(f\"RL : {trans_rl[i]}\")\n",
    "    print(f\"REF: {test_ds[i]['Vietnamese']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:16:16.920203Z",
     "iopub.status.busy": "2025-11-16T11:16:16.919894Z",
     "iopub.status.idle": "2025-11-16T11:16:17.157028Z",
     "shell.execute_reply": "2025-11-16T11:16:17.156365Z",
     "shell.execute_reply.started": "2025-11-16T11:16:16.920180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bleu_sft = bleu_sft     # BLEU model SFT\n",
    "bleu_rl = bleu_rl       # BLEU model RL\n",
    "\n",
    "# Danh sách mô hình và BLEU tương ứng\n",
    "models = ['SFT Model', 'RL Model']\n",
    "bleu_scores = [bleu_sft, bleu_rl]\n",
    "\n",
    "# ============================================================\n",
    "# VẼ BIỂU ĐỒ CỘT\n",
    "# ============================================================\n",
    "plt.figure(figsize=(6, 5))\n",
    "bars = plt.bar(models, bleu_scores, color=['skyblue', 'lightcoral'], width=0.5)\n",
    "\n",
    "# Ghi giá trị BLEU lên đầu mỗi cột\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.3, f\"{yval:.2f}\", ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Thêm tiêu đề và trục\n",
    "plt.title(\"So sánh BLEU giữa các mô hình dịch máy\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"BLEU Score\", fontsize=12)\n",
    "plt.xlabel(\"Loại mô hình\", fontsize=12)\n",
    "plt.ylim(0, max(bleu_scores) + 5)\n",
    "\n",
    "# Hiển thị\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:41:14.404854Z",
     "iopub.status.busy": "2025-11-16T11:41:14.404581Z",
     "iopub.status.idle": "2025-11-16T11:41:14.561766Z",
     "shell.execute_reply": "2025-11-16T11:41:14.561191Z",
     "shell.execute_reply.started": "2025-11-16T11:41:14.404835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "bleu_metric = BLEU(effective_order=True)\n",
    "better_examples = []\n",
    "n = len(trans_sft)\n",
    "for i in range(n):\n",
    "    ref = test_ds[i][\"Vietnamese\"]\n",
    "    sft_pred = trans_sft[i]\n",
    "    dpo_pred = trans_rl[i]\n",
    "\n",
    "    bleu_sft = bleu_metric.sentence_score(sft_pred, [ref]).score\n",
    "    bleu_dpo = bleu_metric.sentence_score(dpo_pred, [ref]).score\n",
    "\n",
    "    if bleu_dpo > bleu_sft:\n",
    "        better_examples.append({\n",
    "            \"index\": i,\n",
    "            \"diff\": bleu_dpo - bleu_sft,\n",
    "            \"EN\": test_ds[i][\"English\"],\n",
    "            \"REF\": ref,\n",
    "            \"SFT\": sft_pred,\n",
    "            \"SFT_BLEU\": bleu_sft,\n",
    "            \"DPO\": dpo_pred,\n",
    "            \"DPO_BLEU\": bleu_dpo\n",
    "        })\n",
    "better_examples = sorted(better_examples, key=lambda x: x['diff'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T11:44:10.519520Z",
     "iopub.status.busy": "2025-11-16T11:44:10.519195Z",
     "iopub.status.idle": "2025-11-16T11:44:10.525181Z",
     "shell.execute_reply": "2025-11-16T11:44:10.524309Z",
     "shell.execute_reply.started": "2025-11-16T11:44:10.519493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EN : It is hard to convince John.\n",
      "REF: thật khó để thuyết phục john.\n",
      "SFT: nó khó để đánh giá cao john.\n",
      "DPO: rất khó để thuyết phục john.\n",
      "\n",
      "\n",
      "EN : I brought Tom home\n",
      "REF: tôi đã mang tom về nhà\n",
      "SFT: tôi đã đưa tom về nhà\n",
      "DPO: tôi đã mang tom về nhà\n",
      "\n",
      "\n",
      "EN : He is certain to come.\n",
      "REF: anh ấy chắc chắn sẽ đến\n",
      "SFT: anh ấy chắc chắn đến.\n",
      "DPO: anh ấy chắc chắn sẽ đến.\n",
      "\n",
      "\n",
      "EN : In the same amount of time it would take me to correct all the mistakes in your report, I could write a better report myself\n",
      "REF: trong cùng một khoảng thời gian tôi sẽ phải sửa tất cả các lỗi trong báo cáo của bạn, tôi có thể tự viết một báo cáo tốt hơn\n",
      "SFT: Tôi sẽ dành cho tôi một báo cáo tốt hơn, tôi có thể viết một báo cáo tốt hơn\n",
      "DPO: Trong một khoảng thời gian đó, tôi có thể viết một số sai lầm trong báo cáo của bạn, tôi có thể viết một báo cáo tốt hơn\n",
      "\n",
      "\n",
      "EN : How many people in this room do you think know Tom's last name?\n",
      "REF: bạn nghĩ có bao nhiêu người trong căn phòng này biết họ của tom?\n",
      "SFT: bạn nghĩ bạn biết tên của tom bao nhiêu người trong phòng này?\n",
      "DPO: bạn nghĩ có bao nhiêu người trong phòng này?\n",
      "\n",
      "\n",
      "EN : Tom just stared at Mary without saying a word\n",
      "REF: Tom chỉ nhìn chằm chằm vào mary mà không nói lời nào\n",
      "SFT: Tom chỉ ngồi xuống mary mà không nói một cái gì\n",
      "DPO: Tom chỉ nhìn vào mary mà không nói một cái gì\n",
      "\n",
      "\n",
      "EN : Tom doesn't talk with anyone.\n",
      "REF: Tom không nói chuyện với bất cứ ai.\n",
      "SFT: tom không nói chuyện với ai.\n",
      "DPO: Tom không nói chuyện với ai.\n",
      "\n",
      "\n",
      "EN : I'm too tired to argue.\n",
      "REF: Tôi quá mệt mỏi để tranh luận.\n",
      "SFT: tôi quá mệt mỏi để tranh luận.\n",
      "DPO: Tôi quá mệt mỏi để tranh luận.\n",
      "\n",
      "\n",
      "EN : I'm only doing what needs to be done\n",
      "REF: tôi chỉ đang làm những gì cần phải làm\n",
      "SFT: tôi chỉ làm những gì cần được làm\n",
      "DPO: tôi chỉ làm những gì cần phải được làm\n",
      "\n",
      "\n",
      "EN : I studied there a year ago.\n",
      "REF: tôi đã học ở đó một năm trước.\n",
      "SFT: tôi học đó một năm trước.\n",
      "DPO: tôi đã học đó một năm trước.\n",
      "\n",
      "\n",
      "EN : The pen is on the desk\n",
      "REF: cái bút ở trên bàn\n",
      "SFT: bút chì đang ở trên bàn\n",
      "DPO: bút chì ở trên bàn\n",
      "\n",
      "\n",
      "EN : Tom and Mary sat on the bench, watching people swim.\n",
      "REF: Tom và mary ngồi trên băng ghế, nhìn mọi người bơi.\n",
      "SFT: tom và mary ngồi trên bàn, xem mọi người bơi.\n",
      "DPO: Tom và mary ngồi trên bàn, xem mọi người bơi.\n",
      "\n",
      "\n",
      "EN : This coffee tastes bitter\n",
      "REF: cà phê này có vị đắng\n",
      "SFT: rượu cà phê này có vị rất xấu\n",
      "DPO: rượu cà phê này có vị sốc\n",
      "\n",
      "\n",
      "EN : We studied more than 800 Chinese characters\n",
      "REF: chúng tôi đã nghiên cứu hơn 800 ký tự Trung Quốc\n",
      "SFT: chúng tôi học hơn 800 những cây bút chì của Nhật Bản\n",
      "DPO: chúng tôi đã học hơn 800 những từ tiếng Pháp\n",
      "\n",
      "\n",
      "EN : We're running a little late.\n",
      "REF: chúng ta đang chạy muộn một chút\n",
      "SFT: chúng tôi đang bận rộn\n",
      "DPO: chúng tôi đang chạy một chút sớm.\n"
     ]
    }
   ],
   "source": [
    "for ex in better_examples[:15]:\n",
    "    print(f\"\\n\")\n",
    "    print(f\"EN : {ex['EN']}\")\n",
    "    print(f\"REF: {ex['REF']}\")\n",
    "    print(f\"SFT: {ex['SFT']}\")\n",
    "    print(f\"DPO: {ex['DPO']}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8746892,
     "sourceId": 13746235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8746999,
     "sourceId": 13746374,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
